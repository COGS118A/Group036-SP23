{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994953a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.feather as feather\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data_feather_embededAll'\n",
    "df = pd.read_feather(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fac14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f41011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small[df_small['views'] > 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below we're training the small dataset on a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "df_titles = pd.read_feather('data_feather_embededTitles')\n",
    "df_titles = df_titles.iloc[:10000]\n",
    "df_lyrics = pd.read_feather('data_feather_embededLyrics')\n",
    "df_lyrics = df_lyrics.iloc[:10000]\n",
    "df_else = pd.read_feather('data_feather_embededElse')\n",
    "df_else = df_else.iloc[:10000]\n",
    "df_artists = df_else['artist']\n",
    "df_tags = df_else[['0', '1', '2', '3', '4', '5']]\n",
    "df_age = df_else['song_age']\n",
    "df_views = df_else['views']\n",
    "\n",
    "lyrics = torch.tensor(df_lyrics.values).type('torch.FloatTensor')\n",
    "titles = torch.tensor(df_titles.values).type('torch.FloatTensor')\n",
    "artists = torch.tensor(df_artists.values).unsqueeze(1).type('torch.FloatTensor')\n",
    "age = torch.tensor(df_age.values).unsqueeze(1).type('torch.FloatTensor')\n",
    "tags = torch.tensor(df_tags.values).type('torch.FloatTensor')\n",
    "views = torch.tensor(df_views.values).unsqueeze(1).type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define the neural network architecture\n",
    "class SongViewCountPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SongViewCountPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define a custom dataset\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, lyrics, titles, artists, age, tags, views):\n",
    "        self.lyrics = lyrics\n",
    "        self.titles = titles\n",
    "        self.artists = artists\n",
    "        self.age = age\n",
    "        self.tags = tags\n",
    "        self.views = views\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.views)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lyrics = self.lyrics[index]\n",
    "        titles = self.titles[index]\n",
    "        artists = self.artists[index]\n",
    "        age = self.age[index]\n",
    "        tags = self.tags[index]\n",
    "        views = self.views[index]\n",
    "        return lyrics, titles, artists, age, tags, views\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = SongDataset(lyrics, titles, artists, age, tags, views)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf608bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and optimizer\n",
    "input_size = lyrics.shape[1] + titles.shape[1] + 1 + 1 + tags.shape[1]\n",
    "model = SongViewCountPredictor(input_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for lyrics, titles, artists, age, tags, views in dataloader:\n",
    "        # Forward pass\n",
    "        inputs = torch.cat((lyrics, titles, artists, age, tags), dim=1)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, views)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        # predicted_counts = outputs.squeeze().round().detach().numpy()\n",
    "        # correct = (predicted_counts == view_count.numpy()).sum()\n",
    "        # total_correct += correct\n",
    "        # total_samples += view_count.size(0)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8bf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below we're doing KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e433c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y_train = df_small['views']\n",
    "X_train = df_small.drop(columns=['views'])\n",
    "\n",
    "# Create and train the KNN regressor\n",
    "k = 11  # Number of neighbors\n",
    "knn = KNeighborsRegressor(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f469e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = 9899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25022018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict view counts for a new song\n",
    "new_song_features = pd.DataFrame(df.iloc[tester].drop('views'))  # Features for the new song (numpy array)\n",
    "predicted_view_count = knn.predict(new_song_features.transpose())\n",
    "print(\"Predicted view count:\", predicted_view_count[0])\n",
    "print(\"Actual view count: \", df.iloc[tester]['views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict view counts for a new song\n",
    "df_titles = pd.read_feather('data_feather_embededTitles')\n",
    "df_titles = df_titles.iloc[tester]\n",
    "df_lyrics = pd.read_feather('data_feather_embededLyrics')\n",
    "df_lyrics = df_lyrics.iloc[tester]\n",
    "df_else = pd.read_feather('data_feather_embededElse')\n",
    "df_else = df_else.iloc[tester]\n",
    "df_artists = df_else['artist']\n",
    "df_tags = df_else[['0', '1', '2', '3', '4', '5']]\n",
    "df_age = df_else['song_age']\n",
    "df_views = df_else['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68356764",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = torch.tensor(df_lyrics.values).type('torch.FloatTensor')\n",
    "titles = torch.tensor(df_titles.values).type('torch.FloatTensor')\n",
    "artists = torch.tensor(df_artists).unsqueeze(0).type('torch.FloatTensor')\n",
    "age = torch.tensor(df_age).unsqueeze(0).type('torch.FloatTensor')\n",
    "tags = torch.tensor(df_tags.values).type('torch.FloatTensor')\n",
    "views = torch.tensor(df_views).unsqueeze(0).type('torch.FloatTensor')\n",
    "\n",
    "new_input = torch.cat((lyrics, titles, artists, age, tags), dim=0)\n",
    "predicted_view_count = model(new_input)\n",
    "print(\"Predicted view count:\", predicted_view_count.item())\n",
    "print(\"Actual view count: \", views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed356e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_score = knn.score(X_train, y_train)\n",
    "print(f\"Train R^2 score: {train_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93ef05",
   "metadata": {},
   "source": [
    "# Neural Networks vs KNN vs Random Forest Regression for 100000 datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow.feather as feather\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16414d",
   "metadata": {},
   "source": [
    "First, we organize all our data. This test is using data with 100,000 datapoints that have been pre-processed elsewhere such that the Lyrics and Titles have been word embedded, the tags have been one-hot encoded, the age and views have been transformed, and the artists have been label encoded (though we will probably re-encode the artists by ranking them first and then labeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pull in all our data\n",
    "\n",
    "df_all = pd.read_feather('data_feather_embededAll')\n",
    "df_lyrics = pd.read_feather('data_feather_embededLyrics')\n",
    "df_titles = pd.read_feather('data_feather_embededTitles')\n",
    "df_else = pd.read_feather('data_feather_embededElse')\n",
    "df_artists = df_else['artist']\n",
    "df_tags = df_else[['0', '1', '2', '3', '4', '5']]\n",
    "df_age = df_else['song_age']\n",
    "df_views = df_else['views']\n",
    "\n",
    "dfs = [df_all, df_lyrics, df_titles, df_artists, df_age, df_tags, df_views]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up data into training and testing sets\n",
    "train_idx, test_idx = train_test_split(list(range(0, 100000)), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12cbb5",
   "metadata": {},
   "source": [
    "Setup training for the Neural Network. We will try 3 different sets of hyper-parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22543951",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features in tensor form for neural network (ensure we only use training data here) => Also push to cuda\n",
    "\n",
    "lyrics = torch.tensor(df_lyrics.loc[train_idx].values).type('torch.FloatTensor').to(device)\n",
    "titles = torch.tensor(df_titles.loc[train_idx].values).type('torch.FloatTensor').to(device)\n",
    "artists = torch.tensor(df_artists.loc[train_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)\n",
    "age = torch.tensor(df_age.loc[train_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)\n",
    "tags = torch.tensor(df_tags.loc[train_idx].values).type('torch.FloatTensor').to(device)\n",
    "views = torch.tensor(df_views.loc[train_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define the neural network architectures\n",
    "class SongViewCountPredictor1(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SongViewCountPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 4)\n",
    "        self.fc6 = nn.Linear(4, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class SongViewCountPredictor2(SongViewCountPredictor1):\n",
    "    def __init__(self, input_size):\n",
    "        super(SongViewCountPredictor, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "class SongViewCountPredictor3(SongViewCountPredictor1):\n",
    "    def __init__(self, input_size):\n",
    "        super(SongViewCountPredictor, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sig(self.fc4(x))\n",
    "        x = self.sig(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, lyrics, titles, artists, age, tags, views):\n",
    "        self.lyrics = lyrics\n",
    "        self.titles = titles\n",
    "        self.artists = artists\n",
    "        self.age = age\n",
    "        self.tags = tags\n",
    "        self.views = views\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.views)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lyrics = self.lyrics[index]\n",
    "        titles = self.titles[index]\n",
    "        artists = self.artists[index]\n",
    "        age = self.age[index]\n",
    "        tags = self.tags[index]\n",
    "        views = self.views[index]\n",
    "        return lyrics, titles, artists, age, tags, views\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = SongDataset(lyrics, titles, artists, age, tags, views)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define the model and optimizer (push models to GPU)\n",
    "input_size = lyrics.shape[1] + titles.shape[1] + 1 + 1 + tags.shape[1]\n",
    "model1 = SongViewCountPredictor1(input_size).to(device)\n",
    "model2 = SongViewCountPredictor2(input_size).to(device)\n",
    "model3 = SongViewCountPredictor3(input_size).to(device)\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.005)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.005)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss() # using MSE as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c75e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss1 = 0.0\n",
    "    epoch_loss2 = 0.0\n",
    "    epoch_loss3 = 0.0\n",
    "    for lyrics, titles, artists, age, tags, views in dataloader:\n",
    "        # move batch data to GPU\n",
    "        lyrics = lyrics.to(device)\n",
    "        titles = titles.to(device)\n",
    "        artists = artists.to(device)\n",
    "        age = age.to(device)\n",
    "        tags = tags.to(device)\n",
    "        views = views.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        inputs = torch.cat((lyrics, titles, artists, age, tags), dim=1)\n",
    "        outputs1 = model1(inputs)\n",
    "        outputs2 = model2(inputs)\n",
    "        outputs3 = model3(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss1 = criterion(outputs1, views)\n",
    "        loss2 = criterion(outputs2, views)\n",
    "        loss3 = criterion(outputs3, views)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        optimizer3.zero_grad()\n",
    "        loss3.backward()\n",
    "        optimizer3.step()\n",
    "        \n",
    "        epoch_loss1 += loss1.item()\n",
    "        epoch_loss2 += loss2.item()\n",
    "        epoch_loss3 += loss3.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss1: {epoch_loss1/len(dataloader):.4f}, \\n\n",
    "                                            Loss2: {epoch_loss2/len(dataloader):.4f}, \\n\n",
    "                                            Loss3: {epoch_loss3/len(dataloader):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5977f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform testing data into tensors (ensure we're only locating testing data)\n",
    "\n",
    "lyrics = torch.tensor(df_lyrics.loc[test_idx].values).type('torch.FloatTensor').to(device)\n",
    "titles = torch.tensor(df_titles.loc[test_idx].values).type('torch.FloatTensor').to(device)\n",
    "artists = torch.tensor(df_artists.loc[test_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)\n",
    "age = torch.tensor(df_age.loc[test_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)\n",
    "tags = torch.tensor(df_tags.loc[test_idx].values).type('torch.FloatTensor').to(device)\n",
    "views = torch.tensor(df_views.loc[test_idx].values).unsqueeze(1).type('torch.FloatTensor').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "# Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "\n",
    "dataset_test = SongDataset(lyrics, titles, artists, age, tags, views)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)\n",
    "\n",
    "size = len(dataloader_test.dataset)\n",
    "num_batches = len(dataloader_test)\n",
    "\n",
    "test_loss1, correct1 = 0, 0\n",
    "test_loss2, correct2 = 0, 0\n",
    "test_loss3, correct3 = 0, 0\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "# also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "with torch.no_grad():\n",
    "    for X, y in dataloader_test:\n",
    "        pred1 = model1(X)\n",
    "        pred2 = model2(X)\n",
    "        pred3 = model3(X)\n",
    "        \n",
    "        test_loss1 += loss_fn(pred1, y).item()\n",
    "        correct1 += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        test_loss2 += loss_fn(pred2, y).item()\n",
    "        correct2 += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        test_loss3 += loss_fn(pred3, y).item()\n",
    "        correct3 += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "test_loss1 /= num_batches\n",
    "correct1 /= size\n",
    "\n",
    "test_loss2 /= num_batches\n",
    "correct2 /= size\n",
    "\n",
    "test_loss3 /= num_batches\n",
    "correct3 /= size\n",
    "\n",
    "print(f\"Test Error 1: \\n Accuracy: {(100*correct1):>0.1f}%, Avg loss: {test_loss1:>8f} \\n\n",
    "        Test Error 2: \\n Accuracy: {(100*correct2):>0.1f}%, Avg loss: {test_loss2:>8f} \\n\n",
    "        Test Error 3: \\n Accuracy: {(100*correct3):>0.1f}%, Avg loss: {test_loss3:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e5a7c",
   "metadata": {},
   "source": [
    "Now we train and test our KNN. We will use a GridSearch to find the right hyperparams for this type of algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36721be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-fold cross-validator\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "data = df_all.loc[train_idx]\n",
    "X = data.drop(columns=['views'])\n",
    "y = data['views']\n",
    "\n",
    "parameters = {\"n_neighbors\": list(range(1, 30))}\n",
    "    \n",
    "model = KNeighborsRegressor()\n",
    "grid_search = RandomSearchCV(model, parameters, scoring=\"neg_mean_squared_error\", cv=kfold, n_jobs=-1, verbose=100)\n",
    "print(f\"Fitting KNeighborsRegressor...\")\n",
    "grid_search.fit(X, y)\n",
    "print('\\nKNN Regression Best Params: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing KNN\n",
    "model = KNeighborsRegressor(n_neighbors=_)\n",
    "model.fit(X, y)\n",
    "\n",
    "data = df_all.loc[test_idx]\n",
    "X_test = data.drop(columns=['views'])\n",
    "y_test = data['views']\n",
    "\n",
    "y_test_hat = model.predict(X_test) \n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat) * 100\n",
    "\n",
    "print(\"Accuracy for our testing dataset with tuning is : {:.2f}%\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb68d7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
